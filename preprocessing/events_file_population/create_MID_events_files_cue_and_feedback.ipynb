{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "388fbaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1bb443f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/net/vast-storage.ib.cluster/scratch/scratch/Tue/dclb/mmc/code/preprocessing/events_file_population'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c44e61e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_events_file(MID_stim_locations, subj, run): \n",
    "    dfs = []\n",
    "    for loc in MID_stim_locations:\n",
    "        trial_type = loc.split(\"/\")[-1].split(\".\")[0]\n",
    "        if trial_type == 'NeuHit' and subj == 'HC013' and run == '2': #because this file doesn't have any values\n",
    "            continue\n",
    "        df = pd.read_csv(loc, sep='\\t+',header = None,engine='python')\n",
    "        df.drop(df[df[0] <= 0].index, inplace=True) #because these files have a 0 for the onset (col0) since this event didn't happen we need to ignore that row \n",
    "        numrows_df = df.shape[0]\n",
    "        df[2]=[trial_type for val in range(0,numrows_df)]\n",
    "        dfs.append(df)\n",
    "    all_events = pd.concat(dfs, ignore_index=True)\n",
    "    all_events.columns = ['onset', 'duration', 'trial_type']\n",
    "    all_events.sort_values(by='onset', inplace=True, ascending=True)\n",
    "    \n",
    "    all_events.duration = all_events.duration.astype(float)\n",
    "\n",
    "    #set duration to 2000ms for Cue stimuli and to (next cue stimulus - onset of hit/miss stimulus)\n",
    "    for i in range(all_events.shape[0]):\n",
    "        if 'Cue' in all_events.iat[i,2]:\n",
    "            all_events.iat[i,1] = 2.0\n",
    "        elif i < (all_events.shape[0]-1): #.shape[0] gets rows\n",
    "            dur = all_events.iat[i+1,0] - all_events.iat[i,0]\n",
    "            all_events.iat[i,1] = dur\n",
    "        else:\n",
    "            dur = 317.4 - all_events.iat[i,0]\n",
    "            all_events.iat[i,1] = dur\n",
    "    return all_events\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57f32c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_file_locations = (glob.glob(\"../../../sub-*/ses-*/func/*mid*run-*events.tsv\"))\n",
    "\n",
    "#empty df \n",
    "empty_df = pd.DataFrame({'onset' : [],'duration' : [],'trial_type' : []})\n",
    "\n",
    "#pull from nifti_to_behavioral_run_match.tsv\n",
    "#make sure we don't read in the missing files (marked by 'none')\n",
    "nifti_to_behavioral_run_match = pd.read_csv(\"nifti_to_behavioral_run_match.tsv\", sep = '\\t')\n",
    "\n",
    "events_to_run_match_dict = dict(zip(nifti_to_behavioral_run_match['nifti_filename'], nifti_to_behavioral_run_match['run']))\n",
    "events_to_run_match_dict = {key.split('bold')[0]+'events.tsv': value for key, value in events_to_run_match_dict.items() if key != 'none'}\n",
    "\n",
    "\n",
    "for file_path in events_file_locations:\n",
    "    \n",
    "    split_path = file_path.split('/')\n",
    "    grp, num = re.split('(\\d+)', split_path[3].split(\"-\")[-1])[0:2]\n",
    "    ses = split_path[4].split('-')[-1]\n",
    "    run_old = split_path[-1].split('_')[-2].split('-')[-1]\n",
    "    file = split_path[-1]\n",
    "    \n",
    "    #only focus on mid events.tsv files (ignoring other bold events.tsv files)\n",
    "    if 'mid' in file: \n",
    "        if file in events_to_run_match_dict.keys():\n",
    "            #need to not just select the events.tsv but also make sure they get matched with the right run number\n",
    "            #thus we get the run matching our events.tsv from the dictionary we created from nifti_to_behavioral_run_match.tsv\n",
    "            run = str(events_to_run_match_dict[file])\n",
    "            #get all the behavioral files based on the run number pulled from nifti_to_behavioral_run_match.tsv\n",
    "            MID_stim_locations = (glob.glob(f\"../../../sourcedata/behavioral/{grp}_{num}/{ses}/mid_R{run}/*.txt\")) \n",
    "            all_events = make_events_file(MID_stim_locations,grp+num,run)\n",
    "            all_events.to_csv(file_path, index = False, header=True, sep='\\t', float_format='%.3f')\n",
    "        #will set all mid files of runs we're not considering and all mid files with moco to an empty file with only a header\n",
    "        else:\n",
    "            empty_df.to_csv(file_path, index = False, header=True, sep='\\t')\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1d903c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(929, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nifti_to_behavioral_run_match = pd.read_csv(\"nifti_to_behavioral_run_match.tsv\", sep = '\\t')\n",
    "nifti_to_behavioral_run_match.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f48590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8531ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #don't need this anymore! Leaving here for reference for now :) \n",
    "# #note that I am first doing this just for one subject, one run, and one session, and will then loop later once this works! \n",
    "# MJ_Go = pd.read_csv (\"../../sourcedata/behavioral/HC_009/baseline/SST_R1/MJ_Go.txt\", sep = '\\t',header = None)\n",
    "# MJ_SuccStop = pd.read_csv (\"../../sourcedata/behavioral/HC_009/baseline/SST_R1/MJ_SuccStop.txt\", sep = '\\t',header = None)\n",
    "# MJ_UnsuccStop = pd.read_csv (\"../../sourcedata/behavioral/HC_009/baseline/SST_R1/MJ_UnsuccStop.txt\", sep = '\\t',header = None)\n",
    "# N_Go = pd.read_csv (\"../../sourcedata/behavioral/HC_009/baseline/SST_R1/N_Go.txt\", sep = '\\t',header = None)\n",
    "# N_SuccStop = pd.read_csv (\"../../sourcedata/behavioral/HC_009/baseline/SST_R1/N_SuccStop.txt\", sep = '\\t',header = None)\n",
    "# N_UnsuccStop = pd.read_csv (\"../../sourcedata/behavioral/HC_009/baseline/SST_R1/N_UnsuccStop.txt\", sep = '\\t',header = None)\n",
    "# grp, num = re.split('(\\d+)', 'sub-HC006'.split(\"-\")[-1])[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8e6b0e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subj_grp=\"MM\"\n",
    "# subj_num=\"340\"\n",
    "# session=\"baseline\"\n",
    "# run_num=\"2\"\n",
    "# MID_stim_locations_indiv = (glob.glob(\"../../sourcedata/behavioral/{}_{}/{}/mid_R{}/*.txt\".format(subj_grp,subj_num,session,run_num))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ad802a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs = []\n",
    "# for loc in MID_stim_locations_indiv:\n",
    "#     trial_type = loc.split(\"/\")[-1].split(\".\")[0]\n",
    "#    # if trial_type == 'NeuHit':\n",
    "#    #     continue\n",
    "#     df = pd.read_csv (loc, sep='\\t+',header = None,engine='python')\n",
    "#     df.drop(df[df[0] <= 0].index, inplace=True)\n",
    "#     numrows_df = df.shape[0]\n",
    "#     df[2]=[trial_type for val in range(0,numrows_df)]\n",
    "#     dfs.append(df)\n",
    "# all_events = pd.concat(dfs, ignore_index=True)\n",
    "# all_events.set_axis(['onset', 'duration', 'trial_type'], axis=1,inplace=True)\n",
    "# all_events.sort_values(by='onset', inplace=True, ascending=True)\n",
    "\n",
    "# all_events.duration = all_events.duration.astype(float)\n",
    "\n",
    "# for i in range(all_events.shape[0]):\n",
    "#     if 'Cue' in all_events.iat[i,2]:\n",
    "#         all_events.iat[i,1] = 2.0\n",
    "#     elif i < 95:\n",
    "#         dur = all_events.iat[i+1,0] - all_events.iat[i,0]\n",
    "#         all_events.iat[i,1] = dur\n",
    "#     else:\n",
    "#         dur = 317.4 - all_events.iat[i,0]\n",
    "#         all_events.iat[i,1] = dur\n",
    "        \n",
    "# display(all_events)\n",
    "# print(all_events.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae2a0668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #writing to all applicable events.tsv files (moco and unco) for a particular grp, num, ses, run \n",
    "\n",
    "# events_files_indiv_locations = (glob.glob(\"../../sub-{}{}/ses-{}/func/*sst*run-0{}*events.tsv\".format(subj_grp,subj_num,session,run)))\n",
    "# for file in events_files_indiv_locations:\n",
    "#     all_events.to_csv(file, index = False, header=True, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fa5569",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "690f84a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subj_nums_locations = (glob.glob(\"../../sub-*\"))\n",
    "# subj_nums = list((re.split('(\\d+)', num.split(\"/\")[-1].split(\"-\")[-1])[0:2] for num in subj_nums_locations))\n",
    "# sessions = ['baseline','1year']\n",
    "# runs = ['1','2','3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6976e326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for grp, num, ses, run in subj_nums:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f047e242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ses_locations = (glob.glob(\"../../sub-{}{}/ses-*\".format('HC','009')))\n",
    "# print(ses_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1708026b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OLD:\n",
    "\n",
    "# def make_events_file(MID_stim_locations, subj, run): \n",
    "#     dfs = []\n",
    "#     for loc in MID_stim_locations:\n",
    "#         trial_type = loc.split(\"/\")[-1].split(\".\")[0]\n",
    "#         if trial_type == 'NeuHit' and subj == 'HC013' and run == '2': #because this file doesn't have any values\n",
    "#             continue\n",
    "#         df = pd.read_csv(loc, sep='\\t+',header = None,engine='python')\n",
    "#         print(df[df[0] <= 0])\n",
    "#         df.drop(df[df[0] <= 0].index, inplace=True) #because these files have a 0 for the onset (col0) since this event didn't happen we need to ignore that row \n",
    "#         numrows_df = df.shape[0]\n",
    "#         df[2]=[trial_type for val in range(0,numrows_df)]\n",
    "#         dfs.append(df)\n",
    "#     all_events = pd.concat(dfs, ignore_index=True)\n",
    "#     all_events.set_axis(['onset', 'duration', 'trial_type'], axis=1,inplace=True)\n",
    "#     all_events.sort_values(by='onset', inplace=True, ascending=True)\n",
    "    \n",
    "#     all_events.duration = all_events.duration.astype(float)\n",
    "\n",
    "#     for i in range(all_events.shape[0]):\n",
    "#         if 'Cue' in all_events.iat[i,2]:\n",
    "#             all_events.iat[i,1] = 2.0\n",
    "#         elif i < (all_events.shape[0]-1):\n",
    "#             dur = all_events.iat[i+1,0] - all_events.iat[i,0]\n",
    "#             all_events.iat[i,1] = dur\n",
    "#         else:\n",
    "#             dur = 317.4 - all_events.iat[i,0]\n",
    "#             all_events.iat[i,1] = dur\n",
    "#     return all_events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38af0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OLD:\n",
    "\n",
    "# events_file_locations = (glob.glob(\"../../../sub-*/ses-*/func/*mid*run-*events.tsv\"))\n",
    "\n",
    "# events_dict={}\n",
    "\n",
    "# for events_loc in events_file_locations:\n",
    "#     split_loc = events_loc.split('/')\n",
    "#     grp, num = re.split('(\\d+)', split_loc[3].split(\"-\")[-1])[0:2]\n",
    "#     ses = split_loc[4].split('-')[-1]\n",
    "#     run = split_loc[-1].split('_')[-2].split('-')[-1] \n",
    "#     if run != '3': #because Jodi's lab says to ignore run 3 (doesn't have behavioral files anyways)\n",
    "#         if (grp+num+ses+run not in events_dict.keys()):\n",
    "#             MID_stim_locations = (glob.glob(f\"../../../sourcedata/behavioral/{grp}_{num}/{ses}/mid_R{run}/*.txt\")) \n",
    "#             all_events = make_events_file(MID_stim_locations,grp+num,run)\n",
    "#             events_dict[grp+num+ses+run]=all_events\n",
    "#         else:\n",
    "#             all_events = events_dict[grp+num+ses+run]\n",
    "#         all_events.to_csv(events_loc, index = False, header=True, sep='\\t', float_format='%.3f')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "08a15f47-ea6a-40d7-b54c-a0143cd70d10",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/om2/user/dclb/.miniconda/envs/nilearn/lib/python3.11/site-packages/pandas/core/indexes/base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/om2/user/dclb/.miniconda/envs/nilearn/lib/python3.11/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/om2/user/dclb/.miniconda/envs/nilearn/lib/python3.11/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [53], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m all_events[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/om2/user/dclb/.miniconda/envs/nilearn/lib/python3.11/site-packages/pandas/core/frame.py:3804\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3804\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3806\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/om2/user/dclb/.miniconda/envs/nilearn/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "all_events[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1db36de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'006'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_loc = '../../../sub-HC006/ses-baseline/func/sub-HC006_ses-baseline_task-mid_rec-moco_run-1_events.tsv'.split('/')\n",
    "#re.split('(\\d+)', split_loc[3].split(\"-\")[-1])[0:2]\n",
    "#split_loc[4].split('-')[-1]\n",
    "#split_loc[-1].split('_')[-2].split('-')[-1]\n",
    "grp, num = re.split('(\\d+)', split_loc[3].split(\"-\")[-1])[0:2]\n",
    "num\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
