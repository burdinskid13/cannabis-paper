{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "593eddb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import glob\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52813f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare data from MMJ-Processed_data-2022_05_27-13_58-6858bbe.csv\n",
    "\n",
    "\n",
    "def create_subs_df(group,ses,task,contrast):\n",
    "    effect_size_maps = glob.glob(f'../../../derivatives/task_analysis_volume/first_level/sub-{group}*/ses-{ses}/task-{task}/sub-{group}*_ses-{ses}_task-{task}_rec-unco_run-1_contrast-{contrast}_effect_size.nii.gz')\n",
    "    non_img_data = pd.read_csv(f\"../../../sourcedata/non_imaging_data/MMJ-Processed_data-2022_05_27-13_58-6858bbe.csv\",low_memory=False)\n",
    "\n",
    "    #need to find subjects that have data for this contrast\n",
    "    subs = [path.split('/sub-')[1].split('/')[0] for path in effect_size_maps if path]\n",
    "    subs = ['_'.join([s for s in re.split(r'(MM|HC)', sub) if s]) for sub in subs]\n",
    "    df_subs = pd.DataFrame(subs,columns=['subs'])\n",
    "\n",
    "\n",
    "    #add columns for male and female, that will then be combined to create the group average \n",
    "    grouped_sex = non_img_data.groupby(\"IDS.CHR.Subject\")[\"SBJ.CHR.Sex\"].agg(\"first\")\n",
    "    dict_sex = grouped_sex.to_dict()\n",
    "    df_subs = pd.concat([df_subs,pd.get_dummies(df_subs['subs'].map(dict_sex))],axis=1,copy=False)\n",
    "\n",
    "    #add age, mean-centered\n",
    "    grouped_age = non_img_data.groupby(\"IDS.CHR.Subject\")[\"SBJ.INT.Age\"].agg(\"first\")\n",
    "    dict_age = grouped_age.to_dict()\n",
    "    df_subs['age'] = df_subs['subs'].map(dict_age)\n",
    "    df_subs['age'] = df_subs['age'] - df_subs['age'].mean()\n",
    "\n",
    "    #add CUDIT summed score, mean-centered\n",
    "    if group == 'HC': \n",
    "        grouped_HC_baseline_cudit = non_img_data[non_img_data['SSS.CHR.Time_point'] == 'Screening'].groupby('IDS.CHR.Subject')['INV.INT.CUDIT.Summed_score'].agg(\"first\")\n",
    "        dict_HC_baseline_cudit = grouped_HC_baseline_cudit.to_dict()\n",
    "        df_subs['total_cudit'] = df_subs['subs'].map(dict_HC_baseline_cudit)\n",
    "        df_subs['total_cudit'] = df_subs['total_cudit'] - df_subs['total_cudit'].mean()\n",
    "\n",
    "    else:\n",
    "        if ses == 'baseline':\n",
    "            dict_MM_baseline_cudit = non_img_data[non_img_data['SSS.CHR.Time_point'] == 'Baseline'].groupby('IDS.CHR.Subject')['INV.INT.CUDIT.Summed_score'].agg(\"first\").to_dict()\n",
    "            df_subs['total_cudit'] = df_subs['subs'].map(dict_MM_baseline_cudit)\n",
    "            df_subs['total_cudit'] = df_subs['total_cudit'] - df_subs['total_cudit'].mean()\n",
    "            df_subs['total_cudit'].fillna(0, inplace=True)\n",
    "\n",
    "        else:\n",
    "            dict_MM_1year_cudit = non_img_data[non_img_data['SSS.CHR.Time_point'] == 'One year'].groupby('IDS.CHR.Subject')['INV.INT.CUDIT.Summed_score'].agg(\"first\").to_dict()\n",
    "            df_subs['total_cudit'] = df_subs['subs'].map(dict_MM_1year_cudit)\n",
    "            df_subs['total_cudit'] = df_subs['total_cudit'] - df_subs['total_cudit'].mean()\n",
    "\n",
    "    #add frequency of THC use per month, mean-centered\n",
    "    freq_dict = {'Once or more per day':7,\n",
    "     '5-6 days a week':6,\n",
    "     '3-4 days a week':5,\n",
    "     '1-2 days a week':4,\n",
    "     'Less than once a week':3,\n",
    "     'Less than once every two weeks':2,\n",
    "     'Less than once a month':1,\n",
    "     None:0,\n",
    "     }\n",
    "\n",
    "    if group == 'HC':\n",
    "        #results from screening visit (using this for consistency since CUDIT-R was also collected at screening visit)\n",
    "        dict_HC_screening_THC = non_img_data[non_img_data['SSS.CHR.Time_point'] == 'Screening'].groupby('IDS.CHR.Subject')['TLF.CHR.THC.Frequency_in_month'].agg(\"last\").to_dict()\n",
    "        dict_HC_screening_THC_num = {k:freq_dict[v] for k,v in dict_HC_screening_THC.items()}\n",
    "        df_subs['THC_freq_month'] = df_subs['subs'].map(dict_HC_screening_THC_num)\n",
    "        df_subs['THC_freq_month'] = df_subs['THC_freq_month'] - df_subs['THC_freq_month'].mean()\n",
    "\n",
    "    else:\n",
    "        if ses == 'baseline':     \n",
    "            #results from MRI visit (using this for consistency since CUDIT-R was also collected at MRI visit)\n",
    "            dict_MM_MRIvisit_THC = non_img_data[non_img_data['SSS.CHR.Time_point'] == 'Baseline'].groupby('IDS.CHR.Subject')['TLF.CHR.THC.Frequency_in_month'].agg(\"first\").to_dict()\n",
    "            dict_MM_MRIvisit_THC_num = {k:freq_dict[v] for k,v in dict_MM_MRIvisit_THC.items()}\n",
    "            df_subs['THC_freq_month'] = df_subs['subs'].map(dict_MM_MRIvisit_THC_num)\n",
    "            df_subs['THC_freq_month'] = df_subs['THC_freq_month'] - df_subs['THC_freq_month'].mean()\n",
    "\n",
    "        else:\n",
    "            dict_MM_MRIvisit_THC = non_img_data[non_img_data['SSS.CHR.Time_point'] == 'One year'].groupby('IDS.CHR.Subject')['TLF.CHR.THC.Frequency_in_month'].agg(\"first\").to_dict()\n",
    "            dict_MM_MRIvisit_THC_num = {k:freq_dict[v] for k,v in dict_MM_MRIvisit_THC.items()}\n",
    "            df_subs['THC_freq_month'] = df_subs['subs'].map(dict_MM_MRIvisit_THC_num)\n",
    "            df_subs['THC_freq_month'] = df_subs['THC_freq_month'] - df_subs['THC_freq_month'].mean()\n",
    "    \n",
    "    return df_subs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a7b3791",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare matching data from nback_Accuracy_RTime and nback_Accuracy_RTime_HC\n",
    "\n",
    "def create_merged_df(df_subs,group,ses):\n",
    "    if group == 'HC':\n",
    "        nback_data = pd.read_csv(f\"../../../sourcedata/non_imaging_data/nback_RT_ACC/nback_Accuracy_RTime_HC.csv\",low_memory=False)\n",
    "        nback_data=nback_data.rename(columns = {'subject':'subs'})\n",
    "    else:\n",
    "        nback_data = pd.read_csv(f\"../../../sourcedata/non_imaging_data/nback_RT_ACC/nback_Accuracy_RTime.csv\",low_memory=False)\n",
    "        nback_data=nback_data.rename(columns = {'subject':'subs'})\n",
    "        if ses == 'baseline':\n",
    "            nback_data=nback_data[nback_data['timepoint']=='baseline']\n",
    "        else:\n",
    "            nback_data=nback_data[nback_data['timepoint']=='1year']\n",
    "\n",
    "    nback_data.drop(columns=['timepoint'], inplace = True)\n",
    "\n",
    "    for column in nback_data.columns[1:]:\n",
    "        nback_data[column] = nback_data[column] - nback_data[column].mean()\n",
    "        nback_data[column].fillna(0, inplace=True)\n",
    "\n",
    "    merged_data = pd.merge(df_subs, nback_data, on='subs')\n",
    "    \n",
    "    return merged_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ae695c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(group,ses,task,contrast):\n",
    "    df_subs = create_subs_df(group,ses,task,contrast)\n",
    "    merged_data = create_merged_df(df_subs,group,ses)\n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1695b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_paired_diff(group1_data,group2_data,column):\n",
    "    \n",
    "    subs1 = group1_data['subs']\n",
    "    subs2 = group2_data['subs']\n",
    "    \n",
    "    subs = set(subs1).intersection(set(subs2))\n",
    "    \n",
    "    xdiff = [float(group2_data[group2_data['subs'] == sub][column])-float(group1_data[group1_data['subs'] == sub][column]) for sub in subs]\n",
    "    \n",
    "    return xdiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18e2ee23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform t-test \n",
    "\n",
    "def t_test_between_groups(group1_data,group2_data):\n",
    "    dict_results={}\n",
    "    \n",
    "    for column in group1_data.columns[6:]:\n",
    "        \n",
    "        x1 = group1_data[column]\n",
    "        x2 = group2_data[column]\n",
    "        pop_mean = np.mean(x2)-np.mean(x1)\n",
    "        \n",
    "        tstat, pval = stats.ttest_ind(x1, x2, axis=0, equal_var=True, nan_policy='raise', permutations=None, alternative='two-sided')\n",
    "        \n",
    "        rounded_pop_mean = round(pop_mean,3)\n",
    "        rounded_tstat = round(tstat,3)\n",
    "        rounded_pval = round(pval,3)\n",
    "        \n",
    "        dict_results[column] = {'difference of means':rounded_pop_mean, 't statistic':rounded_tstat, 'p value':rounded_pval}\n",
    "    \n",
    "    return dict_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6bcd1fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform t-test \n",
    "\n",
    "def paired_t_test(group1_data,group2_data):\n",
    "    dict_results={}\n",
    "    \n",
    "    for column in group1_data.columns[6:]:\n",
    "        \n",
    "        xdiff = calc_paired_diff(group1_data,group2_data,column)\n",
    "        pop_mean = np.mean(xdiff)\n",
    "        \n",
    "        tstat, pval = stats.ttest_1samp(xdiff, popmean=0, nan_policy='raise', alternative='two-sided')\n",
    "\n",
    "        rounded_pop_mean = round(pop_mean,3)\n",
    "        rounded_tstat = round(tstat,3)\n",
    "        rounded_pval = round(pval,3)\n",
    "        \n",
    "        dict_results[column] = {'mean difference':rounded_pop_mean, 't statistic':rounded_tstat, 'p value':rounded_pval}\n",
    "        \n",
    "    return dict_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f576e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dfs(group1_data,group1,ses1,group2_data,group2,ses2):\n",
    "    \n",
    "    #create paths to output dir if not exist\n",
    "    derivatives_path = '../../../derivatives'\n",
    "    nilearn_output_path = os.path.join(derivatives_path, 'behavioral', 'task-nback')\n",
    "    if not os.path.isdir(nilearn_output_path):\n",
    "        os.makedirs (nilearn_output_path)\n",
    "        \n",
    "    group1_data.to_csv(f'../../../derivatives/behavioral/task-nback/nback_group-{group1}_ses-{ses1}.csv')\n",
    "    group2_data.to_csv(f'../../../derivatives/behavioral/task-nback/nback_group-{group2}_ses-{ses2}.csv')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e89d4839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MM_baseline_vs._HC_baseline\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC_all</th>\n",
       "      <th>RT_all_cor</th>\n",
       "      <th>ACC_0b</th>\n",
       "      <th>RT_0b_cor</th>\n",
       "      <th>ACC_2b</th>\n",
       "      <th>RT_2b_cor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>difference of means</th>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.683</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.432</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-1.512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t statistic</th>\n",
       "      <td>0.060</td>\n",
       "      <td>0.050</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p value</th>\n",
       "      <td>0.952</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ACC_all  RT_all_cor  ACC_0b  RT_0b_cor  ACC_2b  RT_2b_cor\n",
       "difference of means   -0.002      -0.683   0.002      0.432  -0.007     -1.512\n",
       "t statistic            0.060       0.050  -0.041     -0.038   0.161      0.075\n",
       "p value                0.952       0.960   0.968      0.970   0.872      0.940"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MM_baseline_vs._MM_1year\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC_all</th>\n",
       "      <th>RT_all_cor</th>\n",
       "      <th>ACC_0b</th>\n",
       "      <th>RT_0b_cor</th>\n",
       "      <th>ACC_2b</th>\n",
       "      <th>RT_2b_cor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>difference of means</th>\n",
       "      <td>-0.007</td>\n",
       "      <td>-2.010</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-3.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t statistic</th>\n",
       "      <td>0.205</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p value</th>\n",
       "      <td>0.838</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ACC_all  RT_all_cor  ACC_0b  RT_0b_cor  ACC_2b  RT_2b_cor\n",
       "difference of means   -0.007      -2.010  -0.002     -0.625  -0.012     -3.104\n",
       "t statistic            0.205       0.168   0.044      0.056   0.338      0.195\n",
       "p value                0.838       0.867   0.965      0.955   0.736      0.846"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MM_baseline_vs._MM_1year_(paired)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC_all</th>\n",
       "      <th>RT_all_cor</th>\n",
       "      <th>ACC_0b</th>\n",
       "      <th>RT_0b_cor</th>\n",
       "      <th>ACC_2b</th>\n",
       "      <th>RT_2b_cor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean difference</th>\n",
       "      <td>0.016</td>\n",
       "      <td>3.774</td>\n",
       "      <td>0.019</td>\n",
       "      <td>2.235</td>\n",
       "      <td>0.013</td>\n",
       "      <td>7.272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t statistic</th>\n",
       "      <td>0.448</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p value</th>\n",
       "      <td>0.657</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ACC_all  RT_all_cor  ACC_0b  RT_0b_cor  ACC_2b  RT_2b_cor\n",
       "mean difference    0.016       3.774   0.019      2.235   0.013      7.272\n",
       "t statistic        0.448       0.303   0.415      0.168   0.428      0.520\n",
       "p value            0.657       0.764   0.681      0.868   0.672      0.607"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs = [('MM','HC','baseline','baseline'),('MM','MM','baseline','1year')]\n",
    "\n",
    "\n",
    "output_dfs = {}\n",
    "\n",
    "for group1,group2,ses1,ses2 in inputs:\n",
    "    \n",
    "    group1_data = create_df(group1,ses1,'nback','twoback-zeroback')\n",
    "    group2_data = create_df(group2,ses2,'nback','twoback-zeroback')\n",
    "    \n",
    "    save_dfs(group1_data,group1,ses1,group2_data,group2,ses2)\n",
    "\n",
    "    ttest_2samp = t_test_between_groups(group1_data,group2_data)\n",
    "    \n",
    "    output_dfs[f'{group1}_{ses1}_vs._{group2}_{ses2}'] = pd.DataFrame.from_dict(ttest_2samp)\n",
    "    \n",
    "    if group2=='MM':\n",
    "        ttest_paired = paired_t_test(group1_data,group2_data)\n",
    "        output_dfs[f'{group1}_{ses1}_vs._{group2}_{ses2}_(paired)'] = pd.DataFrame.from_dict(ttest_paired)\n",
    "        \n",
    "\n",
    "for title in output_dfs.keys():\n",
    "    print(title)\n",
    "    display(output_dfs[title])  \n",
    "    output_dfs[title].to_csv(f'../../../derivatives/behavioral/task-nback/nback_ttest_comparison-{title}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccbb52d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
